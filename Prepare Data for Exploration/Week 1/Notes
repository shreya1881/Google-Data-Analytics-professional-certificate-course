-> After asking the correct questions, you need to prepare the data correctly.

-> Process: preparing the data correctly. 
   This is where understanding the different types of data and data structures comes in. Knowing this lets you figure out what type of data is right for the question 
   you're answering. Plus, you'll gain practical skills about how to extract, use, organize, and protect your data.

-> HOW DATA IS COLLECTED
      1. Interviews
      2. Observations
      3. Forms
      4. Questionnaires
      5. Surveys
      6. Cookies
      
-> First-party data: This is data collected by an individual or group using their own resources.

   Second-party data: which is data collected by a group directly from its audience and then sold. 
   
   Third-party data: data collected from outside sources who did not collect it directly. This data might have come from a number of different sources before you 
   investigated it. It might not be as reliable, but that doesn't mean it can't be useful. You'll just want to make sure you check it for accuracy, bias, and
   credibility.
   
-> No matter what kind of data you use, it needs to be inspected for accuracy and trustworthiness. 

-> Data collection considerations:
      1. How thw data will be collected?
      2. Choose data sources
      3. Decide what data to use
      4. How much data to collect
      5. Select the right/correct data type
      6. Determine the time frame

->  A sample is a part of a population that is representative of the population.

-> Qualitative data : it can't be counted, measured, or easily expressed using numbers. Qualitative data is usually listed as a name, category, or description. 

   Quantitative data : which can be measured or counted and then expressed as a number. This is data with a certain quantity, amount, or range.
   
-> Quantitative data can be broken down into discrete or continuous data. 
      1. Discrete Data: data that's counted and has a limited number of values. Discrete data isn't limited to dollar amounts. Examples of other discrete data 
         are stars and points. When partial measurements (half-stars or quarter-points) aren't allowed, the data is discrete. If you don't accept anything other 
         than full stars or points, the data is considered discrete.
      2. Continuous data : It can be measured using a timer, and its value can be shown as a decimal with several places.

-> Qualitative data can be broken down into:
      1. Nominal Data: Nominal data is a type of qualitative data that's categorized without a set order. In other words, this data doesn't have a sequence. 
         Here's a quick example. Let's say you're collecting data about movies. You ask people if they've watched a given movie. Their responses would be in 
         the form of nominal data. They could respond "Yes," "No," or "Not sure." These choices don't have a particular order.
      2. Ordinal data, on the other hand, is a type of qualitative data with a set order or scale. If you asked a group of people to rank a movie from 1 to 5, 
         some might rank it as a 2, others a 4, and so on. These rankings are in order of how much each person liked the movie.

-> Internal data, which is data that lives within a company's own systems. For example, if a movie studio had compiled all of the data in the spreadsheet using 
   only their own collection methods, then it would be their internal data. The great thing about internal data is that it's usually more reliable and easier to
   collect.
   
   External data is, you guessed it, data that lives and is generated outside of an organization. External data becomes particularly valuable when your analysis 
   depends on as many sources as possible. A great thing about this data is that it's structured. 
   
   Structured data is data that's organized in a certain format, such as rows and columns. Spreadsheets and relational databases are two examples of software that 
   can store data in a structured way.
   
   Unstructured data. This is data that is not organized in any easily identifiable manner. Audio and video files are examples of unstructured data because there's 
   no clear way to identify or organize their content. Unstructured data might have internal structure, but the data doesn't fit neatly in rows and columns like 
   structured data.

-> Structured data works nicely within a data model, which is a model that is used for organizing data elements and how they relate to one another. 
   What are data elements? They're pieces of information, such as people's names, account numbers, and addresses. 
   Data models help to keep data consistent and provide a map of how data is organized. This makes it easier for analysts and other stakeholders to make sense of 
   their data and use it for business purposes. 
   In addition to working well within data models, structured data is also useful for databases. This makes it easy for analysts to enter, query, and analyze the 
   data whenever they need to. This also helps make data visualization pretty easy because structured data can be applied directly to charts, graphs, heat maps, 
   dashboards and most other visual representations of data.
   
-> STRUCTURED DATA
      1. Defined data types.
      2. Most often quantitative.
      3. Easy to organize.
      4. Easy to search.
      5. Easy to analyze.
      6. Stored in relational databases and data warehouses.
      7. Contained in rows and columns.
      8. Example: Excel, Google sheets, SQL, customer data, phone records, transaction history etc.
      
-> UNSTRUCTURED DATA
      1. Varied data types.
      2. Most often qualitative data.
      3. Difficult to search.
      4. Provides more freedom for analysis.
      5. Stored in datalakes, data warehouses and NoSQL database.
      6. Cant be put into rows and columns.
      7. Example: Test msg, phone call transcriptions, social media comments, various log files, images, audio, video.

-> What is data modeling?
   Data modeling is the process of creating diagrams that visually represent how data is organized and structured.  These visual representations are called data 
   models. You can think of data modeling as a blueprint of a house. At any point, there might be electricians, carpenters, and plumbers using that blueprint. 
   Each one of these builders has a different relationship to the blueprint, but they all need it to understand the overall structure of the house. Data models
   are similar; different users might have different data needs, but the data model gives them an understanding of the structure as a whole. 
   
   Levels of data modeling
   Each level of data modeling has a different level of detail. 

   pyramid with the three common types of data modeling: conceptual, logical, and physical

   Conceptual data modeling gives a high-level view of the data structure, such as how data interacts across an organization. For example, a conceptual data 
   model may be used to define the business requirements for a new database. A conceptual data model doesn't contain technical details. 

   Logical data modeling focuses on the technical details of a database such as relationships, attributes, and entities. For example, a logical data model defines 
   how individual records are uniquely identified in a database. But it doesn't spell out actual names of database tables. That's the job of a physical data model.

   Physical data modeling depicts how a database operates. A physical data model defines all entities and attributes used; for example, it includes table names, 
   column names, and data types for the database.
   
   Data-modeling techniques
   There are a lot of approaches when it comes to developing data models, but two common methods are the Entity Relationship Diagram (ERD) and the Unified Modeling 
   Language (UML) diagram. ERDs are a visual way to understand the relationship between entities in the data model. UML diagrams are very detailed diagrams that 
   describe the structure of a system by showing the system's entities, attributes, operations, and their relationships. As a junior data analyst, you will need 
   to understand that there are different data modeling techniques, but in practice, you will probably be using your organization’s existing technique. 
   
-> A data type is a specific kind of data attribute that tells what kind of value the data is. In other words, a data type tells you what kind of data you're 
   working with. Data types can be different depending on the query language you're using. 
   
-> DATA TYPES IN SPREADSHEETS
      1. Number
      2. Text or String: text data type, or a string data type, which is a sequence of characters and punctuation that contains textual information.
      3. Boolean

-> In spreadsheets, Rows = Records, Columns = Fields.

-> With wide data, every data subject has a single row with multiple columns to hold the values of various attributes of the subject. Here's some wide data in a 
   spreadsheet. You might remember we discussed this data about the population of Latin and Caribbean countries earlier. For this data set, each row provides all 
   of the population information about one country. Each column shows the population for a different year.
   Wide data lets you easily identify and quickly compare different columns. In our example, the data is arranged alphabetically by country, so you can compare the 
   annual populations of Antigua and Barbuda, Aruba, and the Bahamas by just checking out the values in each column. The wide data format also makes it easy to find
   and compare the countries' populations at different periods of time. For example, by sorting the data, we discover that Brazil had the highest population of all 
   countries in 2010, and the British Virgin Islands had the lowest population of all countries in 2013.
   
-> Okay, now let's explore this data in a long format. Here the data is no longer organized into columns by year. All the years are now in one column with each 
   country, like Argentina, appearing in multiple rows, one for each year of data. This is how long data usually looks. Long data is data in which each row is one 
   time point per subject, so each subject will have data in multiple rows. Our spreadsheet is formatted to show each year of population data.
   Here we see Antigua and Barbuda first. Long data is a great format for storing and organizing data when there's multiple variables for each subject at each time 
   point that we want to observe. With this long data format, we can store and analyze all of this data using fewer columns. Plus, if we added a new variable, like 
   the average age of a population, we'd only need one more column. If we'd use a wide data format instead, we would have needed 10 more columns, one for each year.
   The long data format keeps everything nice and compact. 

-> Data transformation is the process of changing the data’s format, structure, or values. As a data analyst, there is a good chance you will need to transform 
   data at some point to make it easier for you to analyze it. 

   Data transformation usually involves:

      Adding, copying, or replicating data 

      Deleting fields or records 

      Standardizing the names of variables

      Renaming, moving, or combining columns in a database

      Joining one set of data with another

      Saving a file in a different format. For example, saving a spreadsheet as a comma separated values (CSV) file.
      
-> Why transform data?
   Goals for data transformation might be: 

      Data organization: better organized data is easier to use

      Data compatibility: different applications or systems can then use the same data

      Data migration: data with matching formats can be moved from one system to another

      Data merging: data with the same organization can be merged together

      Data enhancement: data can be displayed with more detailed fields 

      Data comparison: apples-to-apples comparisons of the data can then be made 
      
-> Wide data is preferred when :
      Creating tables and charts with a few variables about each subject.
      Comparing straightforward line graphs.

   Long data is preferred when :
      Storing a lot of variables about each subject. For example, 60 years worth of interest rates for each bank.
      Performing advanced statistical analysis or graphing.
