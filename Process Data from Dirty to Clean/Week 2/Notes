-> Most common cause of poor quality data is human error.

-> Dirty data is data that's incomplete, incorrect, or irrelevant to the problem you're trying to solve.
   When you work with dirty data, you can't be sure that your results are correct. In fact, you can pretty much bet they won't be. Earlier, you learned that data 
   integrity is critical to reliable data analytics results, and clean data helps you achieve data integrity.
   
-> Clean data is data that's complete, correct, and relevant to the problem you're trying to solve. When you work with clean data, you'll find that your projects go 
   much more smoothly.

-> Data engineers transform data into a useful format for analysis and give it a reliable infrastructure. This means they develop, maintain, and test databases, 
   data processors and related systems. 
   
   Data warehousing specialists develop processes and procedures to effectively store and organize data. They make sure that data is available, secure, and backed up 
   to prevent loss.

-> Null is an indication that a value does not exist in a data set. Note that it's not the same as a zero. In the case of a survey, a null would mean the customers 
   skipped that question. A zero would mean they provided zero as their response.

-> TYPES OF DIRTY DATA:
   1. Duplicate data - Any data record that shows up more than once.
   2. Outdated data - Any data that is old which should be replaced with newer and more accurate information.
   3. Incomplete data - Any data that is missing important fields.
   4. Incorrect/inaccurate data - Any data that is complete but inaccurate.
   5. Inconsistent data - Any data that uses different formats to represent the same thing.

-> Misspelling, spelling variations, mixed up letters, inconsistent punctuation and typos in general, happen when someone types in a piece of data incorrectly.

-> Field is a single piece of information from a row or column of a spreadsheet. Field length is a tool for determining how many characters can be keyed into a field,
   assigning a certain length to this fields in your spreadsheet is a great way to avoid errors.
   
-> Data validation is a tool for checking the accuracy and quality of data before adding or importing it. Data validation is a form of data cleaning.

-> Validity
   The concept of using data integrity principles to ensure measures conform to defined business rules or constraints.
   
   Accuracy
   The degree of conformity of a measure to a standard or a true value.
   
   Completeness
   The degree to which all required measures are known.
   
   Consistency
   The degree to which a set of measures is equivalent across systems.

-> Before removing unwanted data from the data set, make a copy of the data set and work with the copy.
   Follow procedure step by step:
      1. Remove the duplicates
      2. Remove irrelevant data(data you dont need)
      3. Remove extra spaces or blanks
      4. Fixing misspellings
      5. Inconsistent capitalization
      6. Incorrect punctuation and other typos
      7. Removing formatting
      
-> A merger, which is an agreement that unites two organizations into a single new one.

-> Data merging is the process of combining two or more datasets into a single dataset. 

-> In data analytics, compatibility describes how well two or more datasets are able to work together.
